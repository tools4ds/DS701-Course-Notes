{
  "hash": "750b1077254920dafee3caf00d4a32d3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'Essential Tools: Pandas'\njupyter: python3\ncode-fold: false\n---\n\n::: {.content-visible when-profile=\"web\"}\n## Introduction\n\n[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tools4ds/DS701-Course-Notes/blob/main/ds701_book/jupyter_notebooks/02B-Pandas.ipynb)\n\nIn this lecture we discuss one of most useful Python packages for data \nscience -- Pandas.\n\nWe'll touch on some highlights here, but to learn more, start with the\n[Pandas Getting started tutorials](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html)\n:::\n\n## Pandas\n\n::: {.incremental}\n\n- [Pandas](https://pandas.pydata.org/docs/index.html) is a Python library for data\nmanipulation and analysis with an emphasis on tabular data. \n- It can be used to produce high quality plots and integrates nicely with other\n  libraries that expect NumPy arrays. \n- Knowledge and use of Pandas is essential as a data scientist.\n:::\n\n:::: {.fragment}\nThe most important data structure provided by Pandas is the `DataFrame`\nimplemented in the \n[DataFrame](https://pandas.pydata.org/docs/reference/frame.html) class. \n::::\n\n:::: {.fragment}\nUnlike a numpy array, a `DataFrame` can have columns of different types.\n::::\n\n:::: {.fragment}\nMake it a habit that when you're given a tabular dataset, load it into a `DataFrame`.\n::::\n\n## Fetching, storing and retrieving your data\n\nWe'll work with stock data. A popular python package for this is `yfinance`, but\nthere seems to be some access rate limits which make it more difficult to use.\n\nInstead we'll manually download a CSV file:\n\n    MANUAL DOWNLOAD FROM WALL STREET JOURNAL:\n    \n    1. Go to: https://www.wsj.com/market-data/quotes/NVDA/historical-prices\n    2. Set date range: January 1, 2024 to December 31, 2024\n    3. Click \"Download\" button\n    4. Save the CSV file\n    5. Load in Python:\n\n::: {#da30b7fb .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\n\ntry:\n    nvidia_stocks = pd.read_csv('data/stocks/nvidia_stock_2024.csv', index_col=0)\nexcept FileNotFoundError:\n    url = 'https://raw.githubusercontent.com/tools4ds/DS701-Course-Notes/main/ds701_book/data/stocks/nvidia_stock_2024.csv'\n    nvidia_stocks = pd.read_csv(url, index_col=0)\n\nnvidia_stocks = nvidia_stocks.sort_index()\n```\n:::\n\n\n---\n\nIt's important to inspect the data you are working with and Pandas provides a\nvariety of methods to do so such as `.head()`, `.tail()`, `.info()`,\n`.describe()`, etc.\n\n::: {#79db76d0 .cell execution_count=3}\n``` {.python .cell-code code-fold=\"false\"}\nnvidia_stocks.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=292}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>01/02/24</th>\n      <td>49.244</td>\n      <td>49.2950</td>\n      <td>47.595</td>\n      <td>48.168</td>\n      <td>4.112542e+08</td>\n    </tr>\n    <tr>\n      <th>01/03/24</th>\n      <td>47.485</td>\n      <td>48.1841</td>\n      <td>47.320</td>\n      <td>47.569</td>\n      <td>3.208962e+08</td>\n    </tr>\n    <tr>\n      <th>01/04/24</th>\n      <td>47.767</td>\n      <td>48.5000</td>\n      <td>47.508</td>\n      <td>47.998</td>\n      <td>3.065349e+08</td>\n    </tr>\n    <tr>\n      <th>01/05/24</th>\n      <td>48.462</td>\n      <td>49.5470</td>\n      <td>48.306</td>\n      <td>49.097</td>\n      <td>4.150393e+08</td>\n    </tr>\n    <tr>\n      <th>01/08/24</th>\n      <td>49.512</td>\n      <td>52.2750</td>\n      <td>49.479</td>\n      <td>52.253</td>\n      <td>6.425099e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNotice how each row has a label and each column has a label.\n\n---\n\nA DataFrame is a python object that has many associated methods to explore and\nmanipulate the data.\n\nThe method `.info()` gives you a description of the dataframe.\n\n::: {#2e94e108 .cell execution_count=4}\n``` {.python .cell-code}\nnvidia_stocks.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nIndex: 252 entries, 01/02/24 to 12/31/24\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Open    252 non-null    float64\n 1   High    252 non-null    float64\n 2   Low     252 non-null    float64\n 3   Close   252 non-null    float64\n 4   Volume  252 non-null    float64\ndtypes: float64(5)\nmemory usage: 11.8+ KB\n```\n:::\n:::\n\n\n---\n\nThe method `.describe()` gives you summary statistics of the dataframe.\n\n::: {#31468735 .cell execution_count=5}\n``` {.python .cell-code}\nnvidia_stocks.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=294}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>2.520000e+02</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>107.899121</td>\n      <td>109.852719</td>\n      <td>105.631198</td>\n      <td>107.825438</td>\n      <td>3.773571e+08</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>27.145281</td>\n      <td>27.437677</td>\n      <td>26.575767</td>\n      <td>26.957320</td>\n      <td>1.618595e+08</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>47.485000</td>\n      <td>48.184100</td>\n      <td>47.320000</td>\n      <td>47.569000</td>\n      <td>1.051570e+08</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>87.740500</td>\n      <td>89.479750</td>\n      <td>86.128550</td>\n      <td>87.751500</td>\n      <td>2.498443e+08</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>115.950000</td>\n      <td>117.090000</td>\n      <td>111.791500</td>\n      <td>115.295000</td>\n      <td>3.508633e+08</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>130.282500</td>\n      <td>133.542500</td>\n      <td>128.235000</td>\n      <td>130.462500</td>\n      <td>4.752442e+08</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>149.350000</td>\n      <td>152.890000</td>\n      <td>146.260000</td>\n      <td>148.880000</td>\n      <td>1.142269e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Writing/Reading to/from a ``.csv`` file\n\nPandas can read and write dataframes with many file formats such as `.csv`, `.json`, `.parquet`,\n`.xlsx`, `.html`, `SQL`, etc.\n\nHere we write the dataframe to a `.csv` file.\n\n::: {#a58e2751 .cell execution_count=6}\n``` {.python .cell-code}\nnvidia_stocks.to_csv('nvidia_data.csv')\n```\n:::\n\n\nWe can escape a shell command using the `!` operator to see the top of the file.\n\n::: {#fb74c944 .cell execution_count=7}\n``` {.python .cell-code}\n!head nvidia_data.csv\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDate,Open,High,Low,Close,Volume\r\n01/02/24,49.244,49.295,47.595,48.168,411254215.887458\r\n01/03/24,47.485,48.1841,47.32,47.569,320896186.791038\r\n01/04/24,47.767,48.5,47.508,47.998,306534876.934651\r\n01/05/24,48.462,49.547,48.306,49.097,415039295.849607\r\n01/08/24,49.512,52.275,49.479,52.253,642509873.574901\r\n01/09/24,52.401,54.325,51.69,53.14,773100072.268999\r\n01/10/24,53.616,54.6,53.489,54.35,533795774.662042\r\n01/11/24,54.999,55.346,53.56,54.822,596758784.032412\r\n01/12/24,54.62,54.97,54.3301,54.71,352993586.470064\r\n```\n:::\n:::\n\n\n---\n\nAnd of course we can likewise read a `.csv` file into a dataframe.  This is probably the most common way you will get data into Pandas.\n\n::: {#55940cc9 .cell execution_count=8}\n``` {.python .cell-code}\ndf = pd.read_csv('nvidia_data.csv')\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=297}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01/02/24</td>\n      <td>49.244</td>\n      <td>49.2950</td>\n      <td>47.595</td>\n      <td>48.168</td>\n      <td>4.112542e+08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/03/24</td>\n      <td>47.485</td>\n      <td>48.1841</td>\n      <td>47.320</td>\n      <td>47.569</td>\n      <td>3.208962e+08</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/04/24</td>\n      <td>47.767</td>\n      <td>48.5000</td>\n      <td>47.508</td>\n      <td>47.998</td>\n      <td>3.065349e+08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/05/24</td>\n      <td>48.462</td>\n      <td>49.5470</td>\n      <td>48.306</td>\n      <td>49.097</td>\n      <td>4.150393e+08</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/08/24</td>\n      <td>49.512</td>\n      <td>52.2750</td>\n      <td>49.479</td>\n      <td>52.253</td>\n      <td>6.425099e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.callout-caution}\nBut be careful, the index column is not automatically set.\n:::\n\n::: {#41a83a14 .cell execution_count=9}\n``` {.python .cell-code}\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 252 entries, 0 to 251\nData columns (total 6 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Date    252 non-null    object \n 1   Open    252 non-null    float64\n 2   High    252 non-null    float64\n 3   Low     252 non-null    float64\n 4   Close   252 non-null    float64\n 5   Volume  252 non-null    float64\ndtypes: float64(5), object(1)\nmemory usage: 11.9+ KB\n```\n:::\n:::\n\n\nNote the index description.\n\n---\n\nTo set the index column, we can use the `index_col` parameter.\n\n::: {#d34d6906 .cell execution_count=10}\n``` {.python .cell-code}\ndf = pd.read_csv('nvidia_data.csv', index_col=0)\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nIndex: 252 entries, 01/02/24 to 12/31/24\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Open    252 non-null    float64\n 1   High    252 non-null    float64\n 2   Low     252 non-null    float64\n 3   Close   252 non-null    float64\n 4   Volume  252 non-null    float64\ndtypes: float64(5)\nmemory usage: 11.8+ KB\n```\n:::\n:::\n\n\n## Working with data columns\n\nIn general, we'll typically describe the rows in the dataframe as **items** \n(or **observations** or **data samples**) and the columns as **features**.\n\n::: {#44c446bb .cell execution_count=11}\n``` {.python .cell-code}\ndf.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=300}\n```\nIndex(['Open', 'High', 'Low', 'Close', 'Volume'], dtype='object')\n```\n:::\n:::\n\n\nPandas allows you to reference a column similar to a python dictionary key,\nusing column names in square brackets.\n\n::: {#8fb87bf8 .cell execution_count=12}\n``` {.python .cell-code}\ndf['Open']\n```\n\n::: {.cell-output .cell-output-display execution_count=301}\n```\nDate\n01/02/24     49.244\n01/03/24     47.485\n01/04/24     47.767\n01/05/24     48.462\n01/08/24     49.512\n             ...   \n12/24/24    140.000\n12/26/24    139.700\n12/27/24    138.550\n12/30/24    134.830\n12/31/24    138.030\nName: Open, Length: 252, dtype: float64\n```\n:::\n:::\n\n\nNote that this returns a `Series` object, the other fundamental data structure in Pandas.\n\n::: {#e2f8d4cc .cell execution_count=13}\n``` {.python .cell-code}\ntype(df['Open'])\n```\n\n::: {.cell-output .cell-output-display execution_count=302}\n```\npandas.core.series.Series\n```\n:::\n:::\n\n\nAlso note that Series is indexed in this case by dates rather than simple integers.\n\n---\n\nPandas also allows you to refer to columns using an object attribute syntax.\n\nNote that the column name cannot include a space in this case.\n\n::: {#11357beb .cell execution_count=14}\n``` {.python .cell-code}\ndf.Open\n```\n\n::: {.cell-output .cell-output-display execution_count=303}\n```\nDate\n01/02/24     49.244\n01/03/24     47.485\n01/04/24     47.767\n01/05/24     48.462\n01/08/24     49.512\n             ...   \n12/24/24    140.000\n12/26/24    139.700\n12/27/24    138.550\n12/30/24    134.830\n12/31/24    138.030\nName: Open, Length: 252, dtype: float64\n```\n:::\n:::\n\n\n---\n\nYou can select a list of columns:\n\n::: {#0e280650 .cell execution_count=15}\n``` {.python .cell-code}\ndf[['Open', 'Close']].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=304}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>Close</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>01/02/24</th>\n      <td>49.244</td>\n      <td>48.168</td>\n    </tr>\n    <tr>\n      <th>01/03/24</th>\n      <td>47.485</td>\n      <td>47.569</td>\n    </tr>\n    <tr>\n      <th>01/04/24</th>\n      <td>47.767</td>\n      <td>47.998</td>\n    </tr>\n    <tr>\n      <th>01/05/24</th>\n      <td>48.462</td>\n      <td>49.097</td>\n    </tr>\n    <tr>\n      <th>01/08/24</th>\n      <td>49.512</td>\n      <td>52.253</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWhich is just another dataframe, which is why we can chain the `.head()` method.\n\n::: {#b1832683 .cell execution_count=16}\n``` {.python .cell-code}\ntype(df[['Open', 'Close']])\n```\n\n::: {.cell-output .cell-output-display execution_count=305}\n```\npandas.core.frame.DataFrame\n```\n:::\n:::\n\n\n---\n\nChanging column names is as simple as assigning to the `.columns` property.\n\nLet's adjust the column names to remove spaces.\n\n::: {#900c71bf .cell execution_count=17}\n``` {.python .cell-code}\nnew_column_names = [x.lower().replace(' ', '_') for x in df.columns]\ndf.columns = new_column_names\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nIndex: 252 entries, 01/02/24 to 12/31/24\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   open    252 non-null    float64\n 1   high    252 non-null    float64\n 2   low     252 non-null    float64\n 3   close   252 non-null    float64\n 4   volume  252 non-null    float64\ndtypes: float64(5)\nmemory usage: 19.9+ KB\n```\n:::\n:::\n\n\nObserve that we first created a list of column names without spaces using __list comprehension__. This is the pythonic way to generate a new list.\n\nNow **all** columns can be accessed using the **dot** notation.\n\n\n## A sampling of DataFrame methods.\n\nThere are many useful methods in the DataFrame object. It is important to\nfamiliarize yourself with these methods.\n\nThe following methods calculate the mean, standard deviation, and median of the specified numeric columns.\n\n::: {#0a7780dc .cell execution_count=18}\n``` {.python .cell-code}\ndf.mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=307}\n```\nopen      1.078991e+02\nhigh      1.098527e+02\nlow       1.056312e+02\nclose     1.078254e+02\nvolume    3.773571e+08\ndtype: float64\n```\n:::\n:::\n\n\nor we can give a list of columns to the Dataframe object:\n\n::: {#d78b0410 .cell execution_count=19}\n``` {.python .cell-code}\ndf[['open', 'close', 'volume']].mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=308}\n```\nopen      1.078991e+02\nclose     1.078254e+02\nvolume    3.773571e+08\ndtype: float64\n```\n:::\n:::\n\n\n::: {#fc6aa3cb .cell execution_count=20}\n``` {.python .cell-code}\ndf.std()\n```\n\n::: {.cell-output .cell-output-display execution_count=309}\n```\nopen      2.714528e+01\nhigh      2.743768e+01\nlow       2.657577e+01\nclose     2.695732e+01\nvolume    1.618595e+08\ndtype: float64\n```\n:::\n:::\n\n\n::: {#4730ceea .cell execution_count=21}\n``` {.python .cell-code}\ndf.median()\n```\n\n::: {.cell-output .cell-output-display execution_count=310}\n```\nopen      1.159500e+02\nhigh      1.170900e+02\nlow       1.117915e+02\nclose     1.152950e+02\nvolume    3.508633e+08\ndtype: float64\n```\n:::\n:::\n\n\nOr apply the method to a single column:\n\n::: {#c189b8f5 .cell execution_count=22}\n``` {.python .cell-code}\ndf.open.mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=311}\n```\nnp.float64(107.89912063492064)\n```\n:::\n:::\n\n\n::: {#e07f290e .cell execution_count=23}\n``` {.python .cell-code}\ndf.high.mean()\n```\n\n::: {.cell-output .cell-output-display execution_count=312}\n```\nnp.float64(109.85271904761905)\n```\n:::\n:::\n\n\n## Plotting methods\n\nPandas also wraps `matplotlib` and provides a variety of easy-to-use plotting\nfunctions directly from the dataframe object.\n\nThese are your \"first look\" functions and useful in exploratory data analysis.\n\nLater, we will use more specialized graphics packages to create more\nsophisticated visualizations.\n\n::: {#c3c37e02 .cell execution_count=24}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\ndf.high.plot(label='High')\ndf.low.plot(label='Low')\nplt.title('NVIDIA Stock Price')\nplt.ylabel('Dollars')\nplt.legend(loc='best')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](02B-Pandas_files/figure-html/cell-24-output-1.png){width=597 height=449}\n:::\n:::\n\n\n---\n\nOr a histogram on the adjusted closing price.\n\n::: {#8c18b160 .cell execution_count=25}\n``` {.python .cell-code}\ndf.close.hist()\nplt.xlabel('Closing Price')\nplt.ylabel('Dollars')\nplt.title('NVIDIA Stock Price')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](02B-Pandas_files/figure-html/cell-25-output-1.png){width=585 height=449}\n:::\n:::\n\n\n## Accessing rows of the DataFrame\n\nSo far we've seen how to access a column of the DataFrame. To access a row we use different syntax.\n\nTo access a row by its index label, use the **`.loc()`** method ('location').\n\n::: {#0a21490d .cell execution_count=26}\n``` {.python .cell-code}\ndf.loc['01/02/24']\n```\n\n::: {.cell-output .cell-output-display execution_count=315}\n```\nopen      4.924400e+01\nhigh      4.929500e+01\nlow       4.759500e+01\nclose     4.816800e+01\nvolume    4.112542e+08\nName: 01/02/24, dtype: float64\n```\n:::\n:::\n\n\nAs a tangent, we can use the `.apply()` method to format the output.\n\n::: {#30d7917f .cell execution_count=27}\n``` {.python .cell-code}\ndf.loc['01/02/24'].apply(lambda x: '{:,.2f}'.format(x) if isinstance(x, (int, float)) else x)\n```\n\n::: {.cell-output .cell-output-display execution_count=316}\n```\nopen               49.24\nhigh               49.30\nlow                47.59\nclose              48.17\nvolume    411,254,215.89\nName: 01/02/24, dtype: object\n```\n:::\n:::\n\n\n---\n\nTo access a row by its index number (i.e., like an array index), use **`.iloc()`** ('integer location')\n\n::: {#e3fc4d96 .cell execution_count=28}\n``` {.python .cell-code}\ndf.iloc[0, :]\n```\n\n::: {.cell-output .cell-output-display execution_count=317}\n```\nopen      4.924400e+01\nhigh      4.929500e+01\nlow       4.759500e+01\nclose     4.816800e+01\nvolume    4.112542e+08\nName: 01/02/24, dtype: float64\n```\n:::\n:::\n\n\nand similarly formatted:\n\n::: {#c0792e69 .cell execution_count=29}\n``` {.python .cell-code}\ndf.iloc[0, :].apply(lambda x: '{:,.2f}'.format(x) if isinstance(x, (int, float)) else x)\n```\n\n::: {.cell-output .cell-output-display execution_count=318}\n```\nopen               49.24\nhigh               49.30\nlow                47.59\nclose              48.17\nvolume    411,254,215.89\nName: 01/02/24, dtype: object\n```\n:::\n:::\n\n\n---\n\nTo iterate over the rows you can use **`.iterrows()`**.\n\n::: {#20ba415f .cell execution_count=30}\n``` {.python .cell-code}\nnum_positive_days = 0\nfor idx, row in df.iterrows():\n    if row.close > row.open:\n        num_positive_days += 1\n\nprint(f\"The total number of positive-gain days is {num_positive_days} out of {len(df)} days or as percentage {num_positive_days/len(df):.2%}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe total number of positive-gain days is 134 out of 252 days or as percentage 53.17%\n```\n:::\n:::\n\n\n::: {.callout-note}\nThis is only capturing the intraday gain/loss, not the cumulative inter-day gain/loss.\n:::\n\n## Filtering\n\nIt is easy to select rows from the data.  \n\nAll the operations below return a new Series or DataFrame, which itself can be\ntreated the same way as all Series and DataFrames we have seen so far.\n\n::: {#7f2e8bbf .cell execution_count=31}\n``` {.python .cell-code}\ntmp_high = df.high > 100\ntmp_high.tail()\n```\n\n::: {.cell-output .cell-output-display execution_count=320}\n```\nDate\n12/24/24    True\n12/26/24    True\n12/27/24    True\n12/30/24    True\n12/31/24    True\nName: high, dtype: bool\n```\n:::\n:::\n\n\nSumming a Boolean array is the same as counting the number of `True` values.\n\n::: {#18da24ed .cell execution_count=32}\n``` {.python .cell-code}\nsum(tmp_high)\n```\n\n::: {.cell-output .cell-output-display execution_count=321}\n```\n153\n```\n:::\n:::\n\n\n---\n\nNow, let's select only the rows of `df` that correspond to `tmp_high`. \n\n::: {.callout-note}\nWe can pass a series to the dataframe to select rows.\n:::\n\n::: {#ca925ba7 .cell execution_count=33}\n``` {.python .cell-code}\ndf[tmp_high]\n```\n\n::: {.cell-output .cell-output-display execution_count=322}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>05/23/24</th>\n      <td>102.028</td>\n      <td>106.3200</td>\n      <td>101.520</td>\n      <td>103.799</td>\n      <td>8.350653e+08</td>\n    </tr>\n    <tr>\n      <th>05/24/24</th>\n      <td>104.449</td>\n      <td>106.4750</td>\n      <td>103.000</td>\n      <td>106.469</td>\n      <td>4.294937e+08</td>\n    </tr>\n    <tr>\n      <th>05/28/24</th>\n      <td>110.244</td>\n      <td>114.9390</td>\n      <td>109.883</td>\n      <td>113.901</td>\n      <td>6.527280e+08</td>\n    </tr>\n    <tr>\n      <th>05/29/24</th>\n      <td>113.050</td>\n      <td>115.4920</td>\n      <td>110.901</td>\n      <td>114.825</td>\n      <td>5.574419e+08</td>\n    </tr>\n    <tr>\n      <th>05/30/24</th>\n      <td>114.650</td>\n      <td>115.8192</td>\n      <td>109.663</td>\n      <td>110.500</td>\n      <td>4.873503e+08</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12/24/24</th>\n      <td>140.000</td>\n      <td>141.9000</td>\n      <td>138.650</td>\n      <td>140.220</td>\n      <td>1.051570e+08</td>\n    </tr>\n    <tr>\n      <th>12/26/24</th>\n      <td>139.700</td>\n      <td>140.8500</td>\n      <td>137.730</td>\n      <td>139.930</td>\n      <td>1.165191e+08</td>\n    </tr>\n    <tr>\n      <th>12/27/24</th>\n      <td>138.550</td>\n      <td>139.0200</td>\n      <td>134.710</td>\n      <td>137.010</td>\n      <td>1.705826e+08</td>\n    </tr>\n    <tr>\n      <th>12/30/24</th>\n      <td>134.830</td>\n      <td>140.2700</td>\n      <td>134.020</td>\n      <td>137.490</td>\n      <td>1.677347e+08</td>\n    </tr>\n    <tr>\n      <th>12/31/24</th>\n      <td>138.030</td>\n      <td>138.0700</td>\n      <td>133.830</td>\n      <td>134.290</td>\n      <td>1.556592e+08</td>\n    </tr>\n  </tbody>\n</table>\n<p>153 rows × 5 columns</p>\n</div>\n```\n:::\n:::\n\n\n---\n\nPutting it all together, we can count the number of positive days without iterating over the rows.\n\n::: {#6169f9a2 .cell execution_count=34}\n``` {.python .cell-code}\npositive_days = df[df.close > df.open]\nprint(f\"Total number of positive-gain days is {len(positive_days)}\")\npositive_days.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTotal number of positive-gain days is 134\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=323}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>01/03/24</th>\n      <td>47.485</td>\n      <td>48.1841</td>\n      <td>47.320</td>\n      <td>47.569</td>\n      <td>3.208962e+08</td>\n    </tr>\n    <tr>\n      <th>01/04/24</th>\n      <td>47.767</td>\n      <td>48.5000</td>\n      <td>47.508</td>\n      <td>47.998</td>\n      <td>3.065349e+08</td>\n    </tr>\n    <tr>\n      <th>01/05/24</th>\n      <td>48.462</td>\n      <td>49.5470</td>\n      <td>48.306</td>\n      <td>49.097</td>\n      <td>4.150393e+08</td>\n    </tr>\n    <tr>\n      <th>01/08/24</th>\n      <td>49.512</td>\n      <td>52.2750</td>\n      <td>49.479</td>\n      <td>52.253</td>\n      <td>6.425099e+08</td>\n    </tr>\n    <tr>\n      <th>01/09/24</th>\n      <td>52.401</td>\n      <td>54.3250</td>\n      <td>51.690</td>\n      <td>53.140</td>\n      <td>7.731001e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n---\n\nOr count the number of days with a gain of more than $2.\n\n::: {#5aa673c1 .cell execution_count=35}\n``` {.python .cell-code}\nvery_positive_days = df[(df.close - df.open) > 2]\nprint(f\"Total number of days with gain > $2 is {len(very_positive_days)}\")\nvery_positive_days.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTotal number of days with gain > $2 is 51\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=324}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>01/08/24</th>\n      <td>49.512</td>\n      <td>52.275</td>\n      <td>49.479</td>\n      <td>52.253</td>\n      <td>6.425099e+08</td>\n    </tr>\n    <tr>\n      <th>02/02/24</th>\n      <td>63.974</td>\n      <td>66.600</td>\n      <td>63.690</td>\n      <td>66.160</td>\n      <td>4.765777e+08</td>\n    </tr>\n    <tr>\n      <th>02/22/24</th>\n      <td>75.025</td>\n      <td>78.575</td>\n      <td>74.220</td>\n      <td>78.538</td>\n      <td>8.650997e+08</td>\n    </tr>\n    <tr>\n      <th>03/01/24</th>\n      <td>80.000</td>\n      <td>82.300</td>\n      <td>79.435</td>\n      <td>82.279</td>\n      <td>4.791351e+08</td>\n    </tr>\n    <tr>\n      <th>03/07/24</th>\n      <td>90.158</td>\n      <td>92.767</td>\n      <td>89.602</td>\n      <td>92.669</td>\n      <td>6.081191e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNote that this doesn't the explain the total gain for the year. Why?\n\n## Creating new columns\n\nTo create a new column, simply assign values to it. The column name is similar to a key in a dictionary.\n\nLet's look at the daily change in closing price.\n\n::: {#dcfcfc42 .cell execution_count=36}\n``` {.python .cell-code}\n# Calculate the daily change in closing price\ndf['daily_change'] = df['close'].diff()\n\n# Create the cumulative profit column\ndf['cum_profit'] = df['daily_change'].cumsum()\n\n# Display the first few rows to verify the new column\nprint(df[['close', 'daily_change', 'cum_profit']].head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           close  daily_change  cum_profit\nDate                                      \n01/02/24  48.168           NaN         NaN\n01/03/24  47.569        -0.599      -0.599\n01/04/24  47.998         0.429      -0.170\n01/05/24  49.097         1.099       0.929\n01/08/24  52.253         3.156       4.085\n```\n:::\n:::\n\n\nIt is convenient that `.diff()` by default is the difference between the current and previous row.\n\n---\n\nLet's look at the histogram of the daily change in stock price.\n\n::: {#8ceec569 .cell execution_count=37}\n``` {.python .cell-code}\n# Plot histogram of daily_change\nplt.figure(figsize=(10, 6))\ndf['daily_change'].hist(bins=50, edgecolor='black')\nplt.title('Histogram of Daily Change in Stock Price')\nplt.xlabel('Daily Change')\nplt.ylabel('Frequency')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](02B-Pandas_files/figure-html/cell-37-output-1.png){width=808 height=523}\n:::\n:::\n\n\n---\n\nLet's give each row a `gain` value as a categorical variable.\n\n::: {#d9bc602c .cell execution_count=38}\n``` {.python .cell-code}\nfor idx, row in df.iterrows():\n    if row.daily_change < 0:\n        df.loc[idx,'cat_gain']='negative'\n    elif row.daily_change < 1:\n        df.loc[idx,'cat_gain']='small_gain'\n    elif row.daily_change < 2:\n        df.loc[idx,'cat_gain']='medium_gain'\n    elif row.daily_change >= 2:\n        df.loc[idx,'cat_gain']='large_gain'\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=327}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>daily_change</th>\n      <th>cum_profit</th>\n      <th>cat_gain</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>01/02/24</th>\n      <td>49.244</td>\n      <td>49.2950</td>\n      <td>47.595</td>\n      <td>48.168</td>\n      <td>4.112542e+08</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>01/03/24</th>\n      <td>47.485</td>\n      <td>48.1841</td>\n      <td>47.320</td>\n      <td>47.569</td>\n      <td>3.208962e+08</td>\n      <td>-0.599</td>\n      <td>-0.599</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>01/04/24</th>\n      <td>47.767</td>\n      <td>48.5000</td>\n      <td>47.508</td>\n      <td>47.998</td>\n      <td>3.065349e+08</td>\n      <td>0.429</td>\n      <td>-0.170</td>\n      <td>small_gain</td>\n    </tr>\n    <tr>\n      <th>01/05/24</th>\n      <td>48.462</td>\n      <td>49.5470</td>\n      <td>48.306</td>\n      <td>49.097</td>\n      <td>4.150393e+08</td>\n      <td>1.099</td>\n      <td>0.929</td>\n      <td>medium_gain</td>\n    </tr>\n    <tr>\n      <th>01/08/24</th>\n      <td>49.512</td>\n      <td>52.2750</td>\n      <td>49.479</td>\n      <td>52.253</td>\n      <td>6.425099e+08</td>\n      <td>3.156</td>\n      <td>4.085</td>\n      <td>large_gain</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n---\n\nHere is another, more \"functional\", way to accomplish the same thing.\n\nFirst, let's drop the gain column so we can start fresh.\n\n::: {#86b53a6d .cell execution_count=39}\n``` {.python .cell-code}\ndf.drop('cat_gain', axis=1, inplace=True)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=328}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>daily_change</th>\n      <th>cum_profit</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>01/02/24</th>\n      <td>49.244</td>\n      <td>49.2950</td>\n      <td>47.595</td>\n      <td>48.168</td>\n      <td>4.112542e+08</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>01/03/24</th>\n      <td>47.485</td>\n      <td>48.1841</td>\n      <td>47.320</td>\n      <td>47.569</td>\n      <td>3.208962e+08</td>\n      <td>-0.599</td>\n      <td>-0.599</td>\n    </tr>\n    <tr>\n      <th>01/04/24</th>\n      <td>47.767</td>\n      <td>48.5000</td>\n      <td>47.508</td>\n      <td>47.998</td>\n      <td>3.065349e+08</td>\n      <td>0.429</td>\n      <td>-0.170</td>\n    </tr>\n    <tr>\n      <th>01/05/24</th>\n      <td>48.462</td>\n      <td>49.5470</td>\n      <td>48.306</td>\n      <td>49.097</td>\n      <td>4.150393e+08</td>\n      <td>1.099</td>\n      <td>0.929</td>\n    </tr>\n    <tr>\n      <th>01/08/24</th>\n      <td>49.512</td>\n      <td>52.2750</td>\n      <td>49.479</td>\n      <td>52.253</td>\n      <td>6.425099e+08</td>\n      <td>3.156</td>\n      <td>4.085</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n---\n\nDefine a function that classifies rows, and `apply` it to each row.\n\n::: {#85634b8e .cell execution_count=40}\n``` {.python .cell-code}\ndef namerow(row):\n    if row.daily_change < 0:\n        return 'negative'\n    elif row.daily_change < 1:\n        return 'small_gain'\n    elif row.daily_change < 2:\n        return 'medium_gain'\n    elif row.daily_change >= 2:\n        return 'large_gain'\n\ndf['cat_gain'] = df.apply(namerow, axis=1)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=329}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>daily_change</th>\n      <th>cum_profit</th>\n      <th>cat_gain</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>01/02/24</th>\n      <td>49.244</td>\n      <td>49.2950</td>\n      <td>47.595</td>\n      <td>48.168</td>\n      <td>4.112542e+08</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>01/03/24</th>\n      <td>47.485</td>\n      <td>48.1841</td>\n      <td>47.320</td>\n      <td>47.569</td>\n      <td>3.208962e+08</td>\n      <td>-0.599</td>\n      <td>-0.599</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>01/04/24</th>\n      <td>47.767</td>\n      <td>48.5000</td>\n      <td>47.508</td>\n      <td>47.998</td>\n      <td>3.065349e+08</td>\n      <td>0.429</td>\n      <td>-0.170</td>\n      <td>small_gain</td>\n    </tr>\n    <tr>\n      <th>01/05/24</th>\n      <td>48.462</td>\n      <td>49.5470</td>\n      <td>48.306</td>\n      <td>49.097</td>\n      <td>4.150393e+08</td>\n      <td>1.099</td>\n      <td>0.929</td>\n      <td>medium_gain</td>\n    </tr>\n    <tr>\n      <th>01/08/24</th>\n      <td>49.512</td>\n      <td>52.2750</td>\n      <td>49.479</td>\n      <td>52.253</td>\n      <td>6.425099e+08</td>\n      <td>3.156</td>\n      <td>4.085</td>\n      <td>large_gain</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Understanding pandas DataFrame.groupby()\n\n## Introduction\n\nThe `groupby()` function is one of the most powerful tools in pandas for data analysis. It implements the \"split-apply-combine\" pattern:\n\n1. **Split** your data into groups based on some criteria\n2. **Apply** a function to each group independently\n3. **Combine** the results back into a data structure\n\nThink of it like organizing a deck of cards by suit, then counting how many cards are in each suit, then presenting those counts in a summary table.\n\n## Basic Concept\n\nImagine you have a dataset of student grades:\n\n::: {#e37dda09 .cell execution_count=41}\n``` {.python .cell-code}\nimport pandas as pd\n\ndata = {\n    'student': ['Alice', 'Bob', 'Alice', 'Bob', 'Charlie', 'Charlie'],\n    'subject': ['Math', 'Math', 'English', 'English', 'Math', 'English'],\n    'score': [85, 78, 92, 88, 95, 90]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   student  subject  score\n0    Alice     Math     85\n1      Bob     Math     78\n2    Alice  English     92\n3      Bob  English     88\n4  Charlie     Math     95\n5  Charlie  English     90\n```\n:::\n:::\n\n\n## Example 1: Simple Grouping\n\nLet's find the average score for each student:\n\n::: {#dee74b9f .cell execution_count=42}\n``` {.python .cell-code}\n# Group by student and calculate mean\nresult = df.groupby('student')['score'].mean()\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstudent\nAlice      88.5\nBob        83.0\nCharlie    92.5\nName: score, dtype: float64\n```\n:::\n:::\n\n\n**What happened?**\n\n- pandas split the data into 3 groups (one per student)\n- Applied the `mean()` function to each group's scores\n- Combined the results into a Series indexed by the student names\n\n## Example 2: Multiple Aggregations\n\nYou can apply multiple functions at once:\n\n::: {#09de4bb6 .cell execution_count=43}\n``` {.python .cell-code}\n# Multiple aggregations\nresult = df.groupby('student')['score'].agg(['mean', 'min', 'max', 'count'])\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         mean  min  max  count\nstudent                       \nAlice    88.5   85   92      2\nBob      83.0   78   88      2\nCharlie  92.5   90   95      2\n```\n:::\n:::\n\n\nwhere the list in the `agg()` method is both a list of functions to apply to the column and a list of names for the columns in the resulting DataFrame.\n\n**What happened?**\n\n- pandas split the data into 3 groups (one per student)\n- Applied the `mean()`, `min()`, `max()`, and `count()` functions to each group's scores\n- Combined the results into a DataFrame indexed by the student names with the column names being the functions applied to the scores.\n\n## Example 3: Grouping by Multiple Columns\n\nWhat if we want to see scores grouped by both student AND subject?\n\n::: {#cfc13ef9 .cell execution_count=44}\n``` {.python .cell-code}\n# Group by multiple columns\nresult = df.groupby(['student', 'subject'])['score'].mean()\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstudent  subject\nAlice    English    92.0\n         Math       85.0\nBob      English    88.0\n         Math       78.0\nCharlie  English    90.0\n         Math       95.0\nName: score, dtype: float64\n```\n:::\n:::\n\n\nThis creates a hierarchical index (MultiIndex) with two levels.\n\n## Example 4: Aggregating Multiple Columns\n\nLet's add more data:\n\n::: {#66adde1e .cell execution_count=45}\n``` {.python .cell-code}\ndata = {\n    'student': ['Alice', 'Bob', 'Alice', 'Bob', 'Charlie', 'Charlie'],\n    'subject': ['Math', 'Math', 'English', 'English', 'Math', 'English'],\n    'score': [85, 78, 92, 88, 95, 90],\n    'hours_studied': [5, 3, 6, 4, 7, 5]\n}\n\ndf = pd.DataFrame(data)\n\n# Group by student and get mean of all numeric columns\nresult = df.groupby('student')[['score', 'hours_studied']].mean()\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         score  hours_studied\nstudent                      \nAlice     88.5            5.5\nBob       83.0            3.5\nCharlie   92.5            6.0\n```\n:::\n:::\n\n\n## Example 5: Different Aggregations for Different Columns\n\nYou can apply different functions to different columns:\n\n::: {#496d6017 .cell execution_count=46}\n``` {.python .cell-code}\n# Different aggregations for different columns\nresult = df.groupby('student').agg({\n    'score': ['mean', 'max'],\n    'hours_studied': 'sum'\n})\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        score     hours_studied\n         mean max           sum\nstudent                        \nAlice    88.5  92            11\nBob      83.0  88             7\nCharlie  92.5  95            12\n```\n:::\n:::\n\n\n## Example 6: Using Custom Functions\n\nYou can define your own aggregation functions:\n\n::: {#ea4426a8 .cell execution_count=47}\n``` {.python .cell-code}\n# Custom function: range (max - min)\ndef score_range(x):\n    return x.max() - x.min()\n\nresult = df.groupby('student')['score'].agg([\n    'mean',\n    ('range', score_range)\n])\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         mean  range\nstudent             \nAlice    88.5      7\nBob      83.0     10\nCharlie  92.5      5\n```\n:::\n:::\n\n\nwhere the argument `('range', score_range)` is a tuple with the name of the column in the resulting DataFrame and the function to apply to the column.\n\n**What happened?**\n\n- pandas split the data into 3 groups (one per student)\n- Applied the `mean()` function to the scores column\n- Applied the `score_range()` function to the scores column and named the column `range` in the resulting DataFrame\n- Combined the results into a DataFrame indexed by the student names with the column names being the functions applied to the scores.\n\n\n## Example 7: Filtering Groups\n\nYou can filter out entire groups based on conditions:\n\n::: {#997e0e71 .cell execution_count=48}\n``` {.python .cell-code}\n# Only keep students with average score above 85\nresult = df.groupby('student').filter(lambda x: x['score'].mean() > 85)\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   student  subject  score  hours_studied\n0    Alice     Math     85              5\n2    Alice  English     92              6\n4  Charlie     Math     95              7\n5  Charlie  English     90              5\n```\n:::\n:::\n\n\n## Example 8: Transform - Keeping Original Shape\n\nSometimes you want to add group statistics to your original dataframe:\n\n::: {#9e57e2b6 .cell execution_count=49}\n``` {.python .cell-code}\n# Add a column with each student's average score\ndf['student_avg'] = df.groupby('student')['score'].transform('mean')\nprint(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   student  subject  score  hours_studied  student_avg\n0    Alice     Math     85              5         88.5\n1      Bob     Math     78              3         83.0\n2    Alice  English     92              6         88.5\n3      Bob  English     88              4         83.0\n4  Charlie     Math     95              7         92.5\n5  Charlie  English     90              5         92.5\n```\n:::\n:::\n\n\nNotice how `transform()` returns a Series with the same length as the original DataFrame, broadcasting the group statistic to all rows in that group.\n\n## Example 9: Apply - Maximum Flexibility\n\nThe `apply()` method gives you complete control and can return different shapes:\n\n::: {#cc83a22f .cell execution_count=50}\n``` {.python .cell-code}\n# Use apply() to get multiple statistics per group\ndef analyze_student(group):\n    return pd.Series({\n        'avg_score': group['score'].mean(),\n        'score_range': group['score'].max() - group['score'].min(),\n        'total_hours': group['hours_studied'].sum(),\n        'efficiency': group['score'].mean() / group['hours_studied'].mean()\n    })\n\nresult = df.groupby('student').apply(analyze_student, include_groups=False)\nprint(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         avg_score  score_range  total_hours  efficiency\nstudent                                                 \nAlice         88.5          7.0         11.0   16.090909\nBob           83.0         10.0          7.0   23.714286\nCharlie       92.5          5.0         12.0   15.416667\n```\n:::\n:::\n\n\nNote: Unlike `transform()` which must return the same shape as the input, `apply()` can return aggregated results of any shape.\n\n\n## Example 10: Iterating Over Groups\n\nSometimes you need to process each group separately:\n\n::: {#623bbb1d .cell execution_count=51}\n``` {.python .cell-code}\n# Iterate over groups\nfor name, group in df.groupby('student'):\n    print(f\"\\n{name}'s records:\")\n    print(group)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAlice's records:\n  student  subject  score  hours_studied  student_avg\n0   Alice     Math     85              5         88.5\n2   Alice  English     92              6         88.5\n\nBob's records:\n  student  subject  score  hours_studied  student_avg\n1     Bob     Math     78              3         83.0\n3     Bob  English     88              4         83.0\n\nCharlie's records:\n   student  subject  score  hours_studied  student_avg\n4  Charlie     Math     95              7         92.5\n5  Charlie  English     90              5         92.5\n```\n:::\n:::\n\n\n## Common Aggregation Functions\n\nHere are the most commonly used aggregation functions:\n\n- `count()` - Number of non-null values\n- `sum()` - Sum of values\n- `mean()` - Average of values\n- `median()` - Median value\n- `min()` - Minimum value\n- `max()` - Maximum value\n- `std()` - Standard deviation\n- `var()` - Variance\n- `first()` - First value in group\n- `last()` - Last value in group\n- `size()` - Number of rows (including NaN)\n\n## Example 11: (Synthetic) Sales Data Analysis\n\n::: {#3c450e59 .cell execution_count=52}\n``` {.python .cell-code}\n# Sample sales data\nsales_data = {\n    'date': pd.date_range('2024-01-01', periods=12, freq='ME'),\n    'region': ['North', 'South', 'North', 'South', 'North', 'South',\n               'North', 'South', 'North', 'South', 'North', 'South'],\n    'product': ['A', 'A', 'B', 'B', 'A', 'A', 'B', 'B', 'A', 'A', 'B', 'B'],\n    'sales': [100, 150, 200, 175, 110, 165, 210, 180, 120, 170, 220, 190],\n    'units': [10, 15, 20, 17, 11, 16, 21, 18, 12, 17, 22, 19]\n}\n\nsales_df = pd.DataFrame(sales_data)\nprint(sales_df)\n\n# Comprehensive analysis by region\nanalysis = sales_df.groupby('region').agg({\n    'sales': ['sum', 'mean', 'max'],\n    'units': 'sum',\n    'product': 'count'  # Count of transactions\n})\n\nprint(\"\\nAnalysis:\")\nprint(analysis)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         date region product  sales  units\n0  2024-01-31  North       A    100     10\n1  2024-02-29  South       A    150     15\n2  2024-03-31  North       B    200     20\n3  2024-04-30  South       B    175     17\n4  2024-05-31  North       A    110     11\n5  2024-06-30  South       A    165     16\n6  2024-07-31  North       B    210     21\n7  2024-08-31  South       B    180     18\n8  2024-09-30  North       A    120     12\n9  2024-10-31  South       A    170     17\n10 2024-11-30  North       B    220     22\n11 2024-12-31  South       B    190     19\n\nAnalysis:\n       sales                  units product\n         sum        mean  max   sum   count\nregion                                     \nNorth    960  160.000000  220    96       6\nSouth   1030  171.666667  190   102       6\n```\n:::\n:::\n\n\n## Tips and Best Practices\n\n1. **Reset Index**: After groupby operations, you often want to reset the index:\n\n\n   ::: {#358d9b0d .cell execution_count=53}\n   ``` {.python .cell-code}\n   result = df.groupby('student')['score'].mean().reset_index()\n   print(\"\\nResult:\")\n   print(result)\n   \n   result2 = df.groupby('student')['score'].mean().reset_index()\n   print(\"\\nResult2:\")\n   print(result2)\n   ```\n   \n   ::: {.cell-output .cell-output-stdout}\n   ```\n   \n   Result:\n      student  score\n   0    Alice   88.5\n   1      Bob   83.0\n   2  Charlie   92.5\n   \n   Result2:\n      student  score\n   0    Alice   88.5\n   1      Bob   83.0\n   2  Charlie   92.5\n   ```\n   :::\n   :::\n   \n   \n2. **Naming Aggregations**: Give your aggregated columns meaningful names:\n\n\n   ::: {#76da8c45 .cell execution_count=54}\n   ``` {.python .cell-code}\n   result = df.groupby('student').agg(\n       avg_score=('score', 'mean'),\n       total_hours=('hours_studied', 'sum')\n   )\n   ```\n   :::\n   \n   \n3. **Performance**: For large datasets, groupby is highly optimized in pandas. It's usually faster than writing loops.\n\n4. **Missing Values**: By default, groupby excludes NaN values from groups. Use `dropna=False` to include them:\n\n\n   ::: {#719f7cd0 .cell execution_count=55}\n   ``` {.python .cell-code}\n   df.groupby('student', dropna=False)['score'].mean()\n   ```\n   \n   ::: {.cell-output .cell-output-display execution_count=344}\n   ```\n   student\n   Alice      88.5\n   Bob        83.0\n   Charlie    92.5\n   Name: score, dtype: float64\n   ```\n   :::\n   :::\n   \n   \n5. **Sort Results**: Control sorting with `sort=True/False`:\n\n\n   ::: {#7d8bb3a6 .cell execution_count=56}\n   ``` {.python .cell-code}\n   df.groupby('student', sort=False)['score'].mean()  # Preserve original order\n   ```\n   \n   ::: {.cell-output .cell-output-display execution_count=345}\n   ```\n   student\n   Alice      88.5\n   Bob        83.0\n   Charlie    92.5\n   Name: score, dtype: float64\n   ```\n   :::\n   :::\n   \n   \n## Visualizing Grouped Data\n\nGroupby works seamlessly with pandas plotting:\n\n::: {#3fc8d641 .cell execution_count=57}\n``` {.python .cell-code}\n# Create a bar chart of average scores by student\ndf.groupby('student')['score'].mean().plot(kind='bar')\n```\n\n::: {.cell-output .cell-output-display}\n![](02B-Pandas_files/figure-html/cell-57-output-1.png){width=566 height=463}\n:::\n:::\n\n\n## `groupby()` Summary\n\nThe `groupby()` function is essential for:\n\n- Calculating statistics by category\n- Finding patterns in subgroups\n- Data aggregation and summarization\n- Feature engineering (with transform)\n- Comparative analysis\n\nMaster the split-apply-combine pattern, and you'll unlock powerful data analysis capabilities!\n\n## `groupby()` Practice Exercise\n\nTry this on your own:\n\n::: {#98c4afce .cell execution_count=58}\n``` {.python .cell-code}\n# Create sample data\npractice_data = {\n    'department': ['Sales', 'Sales', 'IT', 'IT', 'HR', 'HR', 'Sales', 'IT'],\n    'employee': ['John', 'Jane', 'Bob', 'Alice', 'Tom', 'Mary', 'Steve', 'Linda'],\n    'salary': [50000, 55000, 65000, 70000, 48000, 52000, 53000, 68000],\n    'experience': [2, 3, 5, 7, 1, 4, 3, 6]\n}\n\npractice_df = pd.DataFrame(practice_data)\n\n# Try to answer:\n# 1. What's the average salary by department?\n# 2. What's the total experience and max salary by department?\n# 3. Add a column showing each employee's salary as a percentage of their department's total?\n```\n:::\n\n\n# Other Pandas Classes\n\nA DataFrame is essentially an annotated 2-D array.\n\nPandas also has annotated versions of 1-D and 3-D arrays.\n\nA 1-D array in Pandas is called a [Series](https://pandas.pydata.org/docs/reference/series.html). \nYou can think of DataFrames as a dictionary of Series.\n\nA 3-D array in Pandas is created using a\n[MultiIndex](https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.html#).\n\nFor more information read the documentation.\n\n\n# In Class Activity\n\n### Iris Flower Analysis with Pandas\n**Duration:** 20-25 minutes | **Teams:** 3 students each\n\n#### Dataset: Iris Flower Dataset\n**Download Instructions:**\nThe Iris dataset is built into seaborn, so no download needed!\n\n::: {#83d22d8a .cell execution_count=59}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\n\n# Load the Iris dataset directly\niris = sns.load_dataset('iris')\n```\n:::\n\n\n#### Team Roles (2 minutes)\n- **Data Loader:** Loads data and explores structure\n- **Data Analyzer:** Performs calculations and filtering  \n- **Data Visualizer:** Creates plots and charts\n\n#### Activity Tasks (20 minutes)\n\n**Phase 1: Data Loading & Exploration (5 minutes)**\n1. Check the shape and column names\n2. Use `.head()`, `.info()`, and `.describe()` to explore the data\n\n```python\n\n# Replace 0 and '[]' with the correct methods on iris\nprint(f\"Dataset shape: {0}\")\nprint(f\"Columns: {['']}\")\n\n# Look at the first few rows\nprint(\"First 5 rows:\")\n\n# Get basic info about the dataset\nprint(\"\\nDataset Info:\")\n\n# Describe the dataset with summary statistics\nprint(\"\\nSummary Statistics:\")\n\n```\n\n**Phase 2: Basic Data Manipulation (8 minutes)**\n1. **Create new columns:**\n   - Add a 'petal_area' column (petal_length × petal_width)\n   - Create a 'sepal_area' column (sepal_length × sepal_width)\n   - Create a 'size_category' column:\n     - 'Small' (petal_area < 2)\n     - 'Medium' (petal_area 2-5) \n     - 'Large' (petal_area > 5)\n\n```python\n# Create petal area column\niris['petal_area'] = ...\n\n# Create sepal area column\niris['sepal_area'] = ...\n\n# Create size category column\ndef categorize_size(petal_area):\n    if ... :\n        return 'Small'\n    elif ... :\n        return 'Medium'\n    else:\n        return 'Large'\n\niris['size_category'] = ...\n\nprint(\"New columns created:\")\nprint(iris[['petal_length', 'petal_width', 'petal_area', 'size_category']].head(10))\n```\n\n2. **Data Filtering:**\n   - Find all 'setosa' species flowers\n   - Filter for large flowers only\n   - Find flowers with sepal_length > 6\n\n```python\n# Find all 'setosa' species flowers\nsetosa_flowers = ...\nprint(f\"Setosa flowers: {len(setosa_flowers)} out of {len(iris)}\")\n\n# Filter for large flowers only\nlarge_flowers = ...\nprint(f\"Large flowers: {len(large_flowers)} out of {len(iris)}\")\n\n# Find flowers with sepal_length > 6\nlong_sepal = ...\nprint(f\"Flowers with sepal_length > 6: {len(long_sepal)} out of {len(iris)}\")\n```\n\n3. **Basic Analysis:**\n   - Count flowers by species\n   - Find average petal length by species\n\n```python\n# Count flowers by species\nspecies_counts = ...\nprint(\"Flowers by species:\")\nprint(species_counts)\n\n# Find average petal length by species\navg_petal_by_species = ...\nprint(\"\\nAverage petal length by species:\")\nprint(avg_petal_by_species)\n```\n\n**Phase 3: Simple Visualizations (7 minutes)**\n1. **Create 2-3 basic plots:**\n   - Histogram of petal length\n   - Bar chart of flower count by species\n   - Scatter plot: sepal_length vs sepal_width\n\n```python\n# Create a figure with subplots\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# 1. Histogram of petal length\naxes[0, 0].hist(iris['petal_length'], bins=15, alpha=0.7, edgecolor='black', color='skyblue')\naxes[0, 0].set_title('Distribution of Petal Length')\naxes[0, 0].set_xlabel('Petal Length (cm)')\naxes[0, 0].set_ylabel('Frequency')\naxes[0, 0].grid(True, alpha=0.3)\n\n# 2. Bar chart of flower count by species\nspecies_counts = iris['species'].value_counts()\nspecies_counts.plot(kind='bar', ax=axes[0, 1], color=['red', 'green', 'blue'])\naxes[0, 1].set_title('Number of Flowers by Species')\naxes[0, 1].set_xlabel('Species')\naxes[0, 1].set_ylabel('Number of Flowers')\naxes[0, 1].tick_params(axis='x', rotation=45)\naxes[0, 1].grid(True, alpha=0.3)\n\n# 3. Scatter plot: sepal_length vs sepal_width\nfor species in iris['species'].unique():\n    data = iris[iris['species'] == species]\n    axes[1, 0].scatter(data['sepal_length'], data['sepal_width'], \n                      alpha=0.7, label=species, s=50)\naxes[1, 0].set_title('Sepal Length vs Sepal Width (by Species)')\naxes[1, 0].set_xlabel('Sepal Length (cm)')\naxes[1, 0].set_ylabel('Sepal Width (cm)')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# 4. Bar chart of size categories (if size_category column exists)\nif 'size_category' in iris.columns:\n    size_categories = iris['size_category'].value_counts()\n    size_categories.plot(kind='bar', ax=axes[1, 1], color=['orange', 'lightgreen', 'lightcoral'])\n    axes[1, 1].set_title('Flowers by Size Category')\n    axes[1, 1].set_xlabel('Size Category')\n    axes[1, 1].set_ylabel('Number of Flowers')\n    axes[1, 1].tick_params(axis='x', rotation=0)\n    axes[1, 1].grid(True, alpha=0.3)\nelse:\n    # Alternative: petal length vs petal width scatter\n    axes[1, 1].scatter(iris['petal_length'], iris['petal_width'], alpha=0.7, s=50)\n    axes[1, 1].set_title('Petal Length vs Petal Width')\n    axes[1, 1].set_xlabel('Petal Length (cm)')\n    axes[1, 1].set_ylabel('Petal Width (cm)')\n    axes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n**Upon Completion:**\n\nExecute all the cells, save and download the notebook and submit to Gradescope.\n\n# Recap\n\nIn this section we got a first glimpse of the Pandas library.\n\nWe learned how to:\n\n* load data from a CSV file\n* inspect the data\n* manipulate the data\n* plot the data\n* access rows and columns of the dataframe\n* filter the data\n* create new columns\n* group the data\n\n",
    "supporting": [
      "02B-Pandas_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}