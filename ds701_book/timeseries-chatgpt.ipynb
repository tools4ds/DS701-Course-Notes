{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic and Deep Learning Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA/SARIMA Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '~/.cache/kagglehub/datasets/chirag19/air-passengers/versions/1/AirPassengers.csv'\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# from statsmodels.datasets.airline import load_pandas\n",
    "#data = load_pandas().data\n",
    "data['Month'] = pd.date_range(start='1949-01', periods=len(data), freq='ME')\n",
    "data.set_index('Month', inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Log transform to stabilize variance\n",
    "data['Log_Passengers'] = np.log(data['#Passengers'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decomposition\n",
    "decomposition = seasonal_decompose(data['Log_Passengers'], model='additive')\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMA model\n",
    "model = SARIMAX(data['Log_Passengers'], \n",
    "                order=(1, 1, 1), \n",
    "                seasonal_order=(1, 1, 1, 12), \n",
    "                freq='ME')\n",
    "results = model.fit()\n",
    "\n",
    "# Summary and diagnostics\n",
    "print(results.summary())\n",
    "results.plot_diagnostics(figsize=(15, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Forecasting\n",
    "forecast = results.get_forecast(steps=24)\n",
    "forecast_index = pd.date_range(data.index[-1] + pd.DateOffset(months=1), periods=24, freq='ME')\n",
    "forecast_values = np.exp(forecast.predicted_mean)  # Convert back from log\n",
    "confidence_intervals = np.exp(forecast.conf_int())\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['#Passengers'], label='Observed')\n",
    "plt.plot(forecast_index, forecast_values, label='Forecast', color='red')\n",
    "plt.fill_between(forecast_index, confidence_intervals.iloc[:, 0], confidence_intervals.iloc[:, 1], color='pink', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Example -- TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: Energy Consumption Dataset (available via UCI Machine Learning Repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data.set_index('date', inplace=True)\n",
    "data = data['Appliances'].resample('H').mean().fillna(method='ffill')  # Resample and fill missing\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data.values.reshape(-1, 1))\n",
    "\n",
    "# Prepare data for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 24\n",
    "X, y = create_sequences(data_scaled, seq_length)\n",
    "X_train, X_test = X[:int(len(X) * 0.8)], X[int(len(X) * 0.8):]\n",
    "y_train, y_test = y[:int(len(y) * 0.8)], y[int(len(y) * 0.8):]\n",
    "\n",
    "# LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(seq_length, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate and predict\n",
    "predictions = model.predict(X_test)\n",
    "predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_rescaled, label='True Values')\n",
    "plt.plot(predictions_rescaled, label='Predicted Values', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Example -- PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: Energy Consumption Dataset (UCI Machine Learning Repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset from https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>...</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-11 17:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>45.53</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>733.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>13.275433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-11 17:10:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>45.56</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>733.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.2</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>18.606195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-11 17:20:00</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.50</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>733.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>28.642668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-11 17:30:00</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>733.8</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>45.410389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 17:40:00</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>733.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>10.084097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Appliances  lights     T1       RH_1    T2       RH_2  \\\n",
       "0  2016-01-11 17:00:00          60      30  19.89  47.596667  19.2  44.790000   \n",
       "1  2016-01-11 17:10:00          60      30  19.89  46.693333  19.2  44.722500   \n",
       "2  2016-01-11 17:20:00          50      30  19.89  46.300000  19.2  44.626667   \n",
       "3  2016-01-11 17:30:00          50      40  19.89  46.066667  19.2  44.590000   \n",
       "4  2016-01-11 17:40:00          60      40  19.89  46.333333  19.2  44.530000   \n",
       "\n",
       "      T3       RH_3         T4  ...         T9   RH_9     T_out  Press_mm_hg  \\\n",
       "0  19.79  44.730000  19.000000  ...  17.033333  45.53  6.600000        733.5   \n",
       "1  19.79  44.790000  19.000000  ...  17.066667  45.56  6.483333        733.6   \n",
       "2  19.79  44.933333  18.926667  ...  17.000000  45.50  6.366667        733.7   \n",
       "3  19.79  45.000000  18.890000  ...  17.000000  45.40  6.250000        733.8   \n",
       "4  19.79  45.000000  18.890000  ...  17.000000  45.40  6.133333        733.9   \n",
       "\n",
       "   RH_out  Windspeed  Visibility  Tdewpoint        rv1        rv2  \n",
       "0    92.0   7.000000   63.000000        5.3  13.275433  13.275433  \n",
       "1    92.0   6.666667   59.166667        5.2  18.606195  18.606195  \n",
       "2    92.0   6.333333   55.333333        5.1  28.642668  28.642668  \n",
       "3    92.0   6.000000   51.500000        5.0  45.410389  45.410389  \n",
       "4    92.0   5.666667   47.666667        4.9  10.084097  10.084097  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = 'energydata_complete.csv'\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "else:\n",
    "    data = pd.read_csv(url)\n",
    "    data.to_csv(file_path, index=False)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe locally if it doesn't exist\n",
    "if not os.path.exists(file_path):\n",
    "    data.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Descriptions\n",
    "\n",
    "| Column | Description |\n",
    "| ---- | ----------- |\n",
    "| date | time year-month-day hour:minute:second |\n",
    "| Appliances | energy use in Wh |\n",
    "| lights | energy use of light fixtures in the house in Wh |\n",
    "| T1 | Temperature in kitchen area, in Celsius |\n",
    "| RH_1 | Humidity in kitchen area, in % |\n",
    "| T2 | Temperature in living room area, in Celsius |\n",
    "| RH_2 | Humidity in living room area, in % |\n",
    "| T3 | Temperature in laundry room area |\n",
    "| RH_3 | Humidity in laundry room area, in % |\n",
    "| T4 | Temperature in office room, in Celsius |\n",
    "| RH_4 | Humidity in office room, in % |\n",
    "| T5 | Temperature in bathroom, in Celsius |\n",
    "| RH_5 | Humidity in bathroom, in % |\n",
    "| T6 | Temperature outside the building (north side), in Celsius |\n",
    "| RH_6 | Humidity outside the building (north side), in % |\n",
    "| T7 | Temperature in ironing room , in Celsius |\n",
    "| RH_7 | Humidity in ironing room, in % |\n",
    "| T8 | Temperature in teenager room 2, in Celsius |\n",
    "| RH_8 | Humidity in teenager room 2, in % |\n",
    "| T9 | Temperature in parents room, in Celsius |\n",
    "| RH_9 | Humidity in parents room, in % |\n",
    "| To | Temperature outside (from Chievres weather station), in Celsius |\n",
    "| Pressure | (from Chievres weather station), in mm Hg |\n",
    "| RH_out | Humidity outside (from Chievres weather station), in % |\n",
    "| Wind speed | (from Chievres weather station), in m/s |\n",
    "| Visibility | (from Chievres weather station), in km |\n",
    "| Tdewpoint | (from Chievres weather station), Â°C |\n",
    "| rv1 | Random variable 1, nondimensional |\n",
    "| rv2 | Random variable 2, nondimensional |\n",
    "\n",
    "Where indicated, hourly data (then interpolated) from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis, rp5.ru. Permission was obtained from Reliable Prognosis for the distribution of the 4.5 months of weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>...</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:00:00</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>45.53</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>733.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>13.275433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:10:00</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.992500</td>\n",
       "      <td>...</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>45.56</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>733.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.2</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>18.606195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:20:00</th>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>45.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.50</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>733.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>28.642668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:30:00</th>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.723333</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>733.8</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>45.410389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:40:00</th>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>733.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>10.084097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Appliances  lights     T1       RH_1    T2       RH_2  \\\n",
       "date                                                                         \n",
       "2016-01-11 17:00:00          60      30  19.89  47.596667  19.2  44.790000   \n",
       "2016-01-11 17:10:00          60      30  19.89  46.693333  19.2  44.722500   \n",
       "2016-01-11 17:20:00          50      30  19.89  46.300000  19.2  44.626667   \n",
       "2016-01-11 17:30:00          50      40  19.89  46.066667  19.2  44.590000   \n",
       "2016-01-11 17:40:00          60      40  19.89  46.333333  19.2  44.530000   \n",
       "\n",
       "                        T3       RH_3         T4       RH_4  ...         T9  \\\n",
       "date                                                         ...              \n",
       "2016-01-11 17:00:00  19.79  44.730000  19.000000  45.566667  ...  17.033333   \n",
       "2016-01-11 17:10:00  19.79  44.790000  19.000000  45.992500  ...  17.066667   \n",
       "2016-01-11 17:20:00  19.79  44.933333  18.926667  45.890000  ...  17.000000   \n",
       "2016-01-11 17:30:00  19.79  45.000000  18.890000  45.723333  ...  17.000000   \n",
       "2016-01-11 17:40:00  19.79  45.000000  18.890000  45.530000  ...  17.000000   \n",
       "\n",
       "                      RH_9     T_out  Press_mm_hg  RH_out  Windspeed  \\\n",
       "date                                                                   \n",
       "2016-01-11 17:00:00  45.53  6.600000        733.5    92.0   7.000000   \n",
       "2016-01-11 17:10:00  45.56  6.483333        733.6    92.0   6.666667   \n",
       "2016-01-11 17:20:00  45.50  6.366667        733.7    92.0   6.333333   \n",
       "2016-01-11 17:30:00  45.40  6.250000        733.8    92.0   6.000000   \n",
       "2016-01-11 17:40:00  45.40  6.133333        733.9    92.0   5.666667   \n",
       "\n",
       "                     Visibility  Tdewpoint        rv1        rv2  \n",
       "date                                                              \n",
       "2016-01-11 17:00:00   63.000000        5.3  13.275433  13.275433  \n",
       "2016-01-11 17:10:00   59.166667        5.2  18.606195  18.606195  \n",
       "2016-01-11 17:20:00   55.333333        5.1  28.642668  28.642668  \n",
       "2016-01-11 17:30:00   51.500000        5.0  45.410389  45.410389  \n",
       "2016-01-11 17:40:00   47.666667        4.9  10.084097  10.084097  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data.set_index('date', inplace=True)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're interested in the `Appliances` column, which is the energy use of the appliances in Wh. \n",
    "\n",
    "First, we'll resample the data to hourly resolution and fill missing values using the forward fill method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ly/jkydg4dj2vs93b_ds7yp5t7r0000gn/T/ipykernel_38583/973969212.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data = data['Appliances'].resample('h').mean().fillna(method='ffill')  # Resample and fill missing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "2016-01-11 17:00:00     55.000000\n",
       "2016-01-11 18:00:00    176.666667\n",
       "2016-01-11 19:00:00    173.333333\n",
       "2016-01-11 20:00:00    125.000000\n",
       "2016-01-11 21:00:00    103.333333\n",
       "Freq: h, Name: Appliances, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data['Appliances'].resample('h').mean().fillna(method='ffill')  # Resample and fill missing\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the values to be between 0 and 1 and convert to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3290, 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data.values.reshape(-1, 1))\n",
    "\n",
    "print(type(data_scaled))\n",
    "print(data_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data for LSTM\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_length):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.data[index:index + self.seq_length]\n",
    "        y = self.data[index + self.seq_length]\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seq_length = 24\n",
    "dataset = TimeSeriesDataset(data_scaled, seq_length)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data into training and testing\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the first batch\n",
    "for X, y in train_loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, output_size=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])  # Use the output of the last time step\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X, y in train_loader:\n",
    "        X = X.unsqueeze(-1)  # Add input dimension\n",
    "        y = y.unsqueeze(-1)  # Add target dimension\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.unsqueeze(-1)\n",
    "        y = y.unsqueeze(-1)\n",
    "        preds = model(X)\n",
    "        predictions.extend(preds.numpy())\n",
    "        actuals.extend(y.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rescale predictions and actuals to original scale\n",
    "predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "actuals_rescaled = scaler.inverse_transform(actuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(actuals_rescaled, label='True Values')\n",
    "plt.plot(predictions_rescaled, label='Predicted Values', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study and Discussion\n",
    "\n",
    "## Real-world case study: Application of time series analysis\n",
    "\n",
    "- **Case Study**: Let's explore a real-world case study where time series analysis is applied.\n",
    "  - **Industry**: Choose an industry (e.g., finance, healthcare, retail).\n",
    "  - **Problem Statement**: Define the problem that needs to be addressed using time series analysis.\n",
    "  - **Data Collection**: Describe the data collection process and the type of data used.\n",
    "  - **Model Selection**: Select appropriate time series models for the analysis.\n",
    "  - **Analysis**: Perform the time series analysis and interpret the results.\n",
    "  - **Outcome**: Discuss the outcomes and how the analysis helped in decision-making.\n",
    "  \n",
    "## Group discussion on potential projects or applications\n",
    "\n",
    "- **Group Discussion**: Let's engage in a group discussion to brainstorm potential projects or applications of time series analysis.\n",
    "  - **Project Ideas**: Share and discuss various project ideas that can benefit from time series analysis.\n",
    "  - **Application Areas**: Identify different application areas such as finance, healthcare, retail, and more.\n",
    "  - **Challenges**: Discuss the potential challenges and limitations of applying time series analysis in these projects.\n",
    "  - **Collaboration**: Explore opportunities for collaboration and knowledge sharing within the group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
