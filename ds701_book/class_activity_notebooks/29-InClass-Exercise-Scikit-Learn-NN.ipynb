{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# In-Class Exercise: Neural Networks with Scikit-Learn\n",
        "\n",
        "**Time: 10 minutes**\n",
        "\n",
        "In this exercise, you'll practice building and evaluating Multi-Layer Perceptrons using scikit-learn's `MLPClassifier` and `MLPRegressor`.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Build an MLP classifier for a multi-class problem\n",
        "- Preprocess data appropriately for neural networks\n",
        "- Evaluate model performance\n",
        "- Compare different architectures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Wine Classification (5 minutes)\n",
        "\n",
        "We'll use the Wine dataset, which contains chemical analysis of wines from three different cultivars.\n",
        "\n",
        "### Task 1.1: Load and split the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the wine dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(y))}\")\n",
        "print(f\"Feature names: {wine.feature_names[:3]}...\")  # First 3 features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Split the data into training (70%) and test (30%) sets\n",
        "# Use random_state=42 for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    # YOUR CODE HERE\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 1.2: Scale the features\n",
        "\n",
        "Neural networks work best with normalized data. Use `StandardScaler` to scale the features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create a StandardScaler and scale both training and test data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = # YOUR CODE HERE\n",
        "X_test_scaled = # YOUR CODE HERE\n",
        "\n",
        "print(f\"Original feature range: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n",
        "print(f\"Scaled feature range: [{X_train_scaled.min():.2f}, {X_train_scaled.max():.2f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 1.3: Build and train an MLP\n",
        "\n",
        "Create an `MLPClassifier` with:\n",
        "- Two hidden layers with 20 and 10 neurons\n",
        "- ReLU activation\n",
        "- Adam solver\n",
        "- max_iter=500\n",
        "- random_state=42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create and train the MLPClassifier\n",
        "mlp = MLPClassifier(\n",
        "    # YOUR CODE HERE - specify the parameters\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "print(\"Training complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 1.4: Evaluate the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Make predictions on the test set\n",
        "y_pred = # YOUR CODE HERE\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=wine.target_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 1.5: Visualize the loss curve\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the training loss curve\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(mlp.loss_curve_)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Curve')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Number of iterations: {mlp.n_iter_}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Architecture Comparison (5 minutes)\n",
        "\n",
        "Now let's compare different neural network architectures!\n",
        "\n",
        "### Task 2.1: Compare different architectures\n",
        "\n",
        "Train MLPs with different hidden layer configurations and compare their performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define different architectures to test\n",
        "architectures = {\n",
        "    'Single Layer (50)': (50,),\n",
        "    'Single Layer (100)': (100,),\n",
        "    'Two Layers (20, 10)': (20, 10),\n",
        "    'Two Layers (50, 25)': (50, 25),\n",
        "    'Three Layers (30, 20, 10)': (30, 20, 10)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# TODO: Train each architecture and store its test accuracy\n",
        "for name, hidden_layers in architectures.items():\n",
        "    mlp = MLPClassifier(\n",
        "        hidden_layer_sizes=hidden_layers,\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        max_iter=500,\n",
        "        random_state=42,\n",
        "        verbose=False\n",
        "    )\n",
        "    \n",
        "    # YOUR CODE HERE: Fit the model and calculate test accuracy\n",
        "    mlp.fit(X_train_scaled, y_train)\n",
        "    accuracy = mlp.score(X_test_scaled, y_test)\n",
        "    \n",
        "    results[name] = accuracy\n",
        "    print(f\"{name:30s}: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2.2: Visualize the comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a bar plot to compare the architectures\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(results.keys(), results.values(), color='steelblue')\n",
        "plt.xlabel('Architecture')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Performance Comparison of Different MLP Architectures')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylim([0.85, 1.0])  # Adjust as needed\n",
        "plt.grid(True, axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bonus Challenge (Optional)\n",
        "\n",
        "If you finish early, try this additional task:\n",
        "\n",
        "### Bonus: Add early stopping\n",
        "\n",
        "Modify your best architecture to use early stopping and see if it improves performance or training time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create an MLP with early stopping\n",
        "mlp_early = MLPClassifier(\n",
        "    hidden_layer_sizes=(50, 25),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=1000,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    n_iter_no_change=10,\n",
        "    random_state=42,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "mlp_early.fit(X_train_scaled, y_train)\n",
        "accuracy_early = mlp_early.score(X_test_scaled, y_test)\n",
        "\n",
        "print(f\"Accuracy with early stopping: {accuracy_early:.4f}\")\n",
        "print(f\"Training stopped at iteration: {mlp_early.n_iter_}\")\n",
        "print(f\"Best validation score: {mlp_early.best_validation_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion Questions\n",
        "\n",
        "1. **Which architecture performed best on the Wine dataset? Why do you think that is?**\n",
        "   \n",
        "   _Your answer here_\n",
        "\n",
        "2. **Did you notice any architectures that were too simple or too complex?**\n",
        "   \n",
        "   _Your answer here_\n",
        "\n",
        "3. **How did early stopping affect the training? Did it help or hurt performance?**\n",
        "   \n",
        "   _Your answer here_\n",
        "\n",
        "4. **When would you choose scikit-learn's MLP over PyTorch for a real project?**\n",
        "   \n",
        "   _Your answer here_\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "- Always **scale/normalize** your data before training neural networks\n",
        "- **Simpler architectures** often work well for smaller datasets\n",
        "- **Early stopping** can prevent overfitting and save training time\n",
        "- Scikit-learn makes it easy to **experiment** with different architectures\n",
        "- Use **cross-validation** and **grid search** to find optimal hyperparameters\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
