## Neural Network Example -- PyTorch

Dataset: Energy Consumption Dataset (UCI Machine Learning Repository)

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
```

Load dataset from https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction

```{python}
import os

file_path = 'energydata_complete.csv'
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv"

if os.path.exists(file_path):
    data = pd.read_csv(file_path)
else:
    data = pd.read_csv(url)
    data.to_csv(file_path, index=False)

data.head()
```

```{python}
# Save the dataframe locally if it doesn't exist
if not os.path.exists(file_path):
    data.to_csv(file_path, index=False)
```

<details>

**Column Descriptions**

<summary>
| Column | Description |
| ---- | ----------- |
| date | time year-month-day hour:minute:second |
| Appliances | energy use in Wh |
| lights | energy use of light fixtures in the house in Wh |
| T1 | Temperature in kitchen area, in Celsius |
| RH_1 | Humidity in kitchen area, in % |
| T2 | Temperature in living room area, in Celsius |
| RH_2 | Humidity in living room area, in % |
| T3 | Temperature in laundry room area |
| RH_3 | Humidity in laundry room area, in % |
| T4 | Temperature in office room, in Celsius |
| RH_4 | Humidity in office room, in % |
| T5 | Temperature in bathroom, in Celsius |
| RH_5 | Humidity in bathroom, in % |
| T6 | Temperature outside the building (north side), in Celsius |
| RH_6 | Humidity outside the building (north side), in % |
| T7 | Temperature in ironing room , in Celsius |
| RH_7 | Humidity in ironing room, in % |
| T8 | Temperature in teenager room 2, in Celsius |
| RH_8 | Humidity in teenager room 2, in % |
| T9 | Temperature in parents room, in Celsius |
| RH_9 | Humidity in parents room, in % |
| To | Temperature outside (from Chievres weather station), in Celsius |
| Pressure | (from Chievres weather station), in mm Hg |
| RH_out | Humidity outside (from Chievres weather station), in % |
| Wind speed | (from Chievres weather station), in m/s |
| Visibility | (from Chievres weather station), in km |
| Tdewpoint | (from Chievres weather station), Â°C |
| rv1 | Random variable 1, nondimensional |
| rv2 | Random variable 2, nondimensional |
</summary>
</details>

Where indicated, hourly data (then interpolated) from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis, rp5.ru. Permission was obtained from Reliable Prognosis for the distribution of the 4.5 months of weather data.

```{python}
data.info()
```

```{python}

data['date'] = pd.to_datetime(data['date'])
data.set_index('date', inplace=True)

data.head()
```

We're interested in the `Appliances` column, which is the energy use of the appliances in Wh. 

First, we'll resample the data to hourly resolution and fill missing values using the forward fill method.

```{python}
data = data['Appliances'].resample('h').mean().fillna(method='ffill')  # Resample and fill missing

data.head()
```

Scale the values to be between 0 and 1 and convert to a numpy array.

```{python}
# Normalize data
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data.values.reshape(-1, 1))

print(type(data_scaled))
print(data_scaled.shape)
```

```{python}

# Prepare data for LSTM
class TimeSeriesDataset(Dataset):
    def __init__(self, data, seq_length):
        self.data = data
        self.seq_length = seq_length

    def __len__(self):
        return len(self.data) - self.seq_length

    def __getitem__(self, index):
        X = self.data[index:index + self.seq_length]
        y = self.data[index + self.seq_length]
        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
```

```{python}

seq_length = 24
dataset = TimeSeriesDataset(data_scaled, seq_length)

print(len(dataset))
```

```{python}

# Split data into training and testing
train_size = int(len(dataset) * 0.8)
test_size = len(dataset) - train_size

train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

print(len(train_loader))
print(len(test_loader))
```

```{python}
# let's look at the first batch
for X, y in train_loader:
    print(X.shape)
    print(y.shape)
    break
```

```{python}

# Define the LSTM model
class LSTMModel(nn.Module):
    def __init__(self, input_size=1, hidden_size=50, output_size=1):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x, _ = self.lstm(x)
        x = self.fc(x[:, -1, :])  # Use the output of the last time step
        return x
```

```{python}
model = LSTMModel()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
```

```{python}
# Train the model
epochs = 20
for epoch in range(epochs):
    model.train()
    train_loss = 0.0
    for X, y in train_loader:
        X = X.unsqueeze(-1)  # Add input dimension
        y = y.unsqueeze(-1)  # Add target dimension

        optimizer.zero_grad()
        outputs = model(X)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()

    print(f"Epoch {epoch+1}/{epochs}, Loss: {train_loss/len(train_loader):.4f}")
```

```{python}

# Evaluate the model
model.eval()
predictions = []
actuals = []
with torch.no_grad():
    for X, y in test_loader:
        X = X.unsqueeze(-1)
        y = y.unsqueeze(-1)
        preds = model(X)
        predictions.extend(preds.numpy())
        actuals.extend(y.numpy())
```

```{python}

# Rescale predictions and actuals to original scale
predictions_rescaled = scaler.inverse_transform(predictions)
actuals_rescaled = scaler.inverse_transform(actuals)
```

```{python}

# Plot results
plt.figure(figsize=(10, 6))
plt.plot(actuals_rescaled, label='True Values')
plt.plot(predictions_rescaled, label='Predicted Values', alpha=0.7)
plt.legend()
plt.show()
```